{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":31041,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install torch transformers scikit-learn matplotlib seaborn tqdm datasets numpy\n!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n!pip install transformers scikit-learn matplotlib seaborn tqdm datasets numpy","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-06-27T04:44:19.862890Z","iopub.execute_input":"2025-06-27T04:44:19.863168Z","execution_failed":"2025-06-27T04:44:50.560Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\nRequirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.51.3)\nRequirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.2.2)\nRequirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.7.2)\nRequirement already satisfied: seaborn in /usr/local/lib/python3.11/dist-packages (0.12.2)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (4.67.1)\nRequirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (3.6.0)\nRequirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (1.26.4)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\nRequirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.13.2)\nRequirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.2)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\nCollecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cublas-cu12==12.4.5.8 (from torch)\n  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cufft-cu12==11.2.1.3 (from torch)\n  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-curand-cu12==10.3.5.147 (from torch)\n  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cusolver-cu12==11.6.1.9 (from torch)\n  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cusparse-cu12==12.3.1.170 (from torch)\n  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nRequirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\nRequirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\nRequirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\nCollecting nvidia-nvjitlink-cu12==12.4.127 (from torch)\n  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nRequirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\nRequirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.31.1)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (25.0)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\nRequirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\nRequirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\nRequirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\nRequirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.15.2)\nRequirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.5.0)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\nRequirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.1)\nRequirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.57.0)\nRequirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\nRequirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (11.1.0)\nRequirement already satisfied: pyparsing<3.1,>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.0.9)\nRequirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (2.9.0.post0)\nRequirement already satisfied: pandas>=0.25 in /usr/local/lib/python3.11/dist-packages (from seaborn) (2.2.3)\nRequirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (19.0.1)\nRequirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.3.8)\nRequirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.5.0)\nRequirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.16)\nCollecting fsspec (from torch)\n  Downloading fsspec-2025.3.0-py3-none-any.whl.metadata (11 kB)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy) (2.4.1)\nRequirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.11.18)\nRequirement already satisfied: hf-xet<2.0.0,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (1.1.0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.25->seaborn) (2025.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.25->seaborn) (2025.2)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.2)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.4.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.4.26)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy) (1.3.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy) (2024.2.0)\nRequirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2.6.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.3.2)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (25.3.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.6.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (6.4.3)\nRequirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (0.3.1)\nRequirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.20.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy) (2024.2.0)\nDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m29.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m18.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading fsspec-2025.3.0-py3-none-any.whl (193 kB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m193.6/193.6 kB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nfrom torch.utils.data import Dataset, DataLoader\nfrom transformers import (\n    DistilBertTokenizer,\n    DistilBertForSequenceClassification,\n    get_linear_schedule_with_warmup,\n    pipeline,\n    BartForConditionalGeneration,\n    BartTokenizer\n)\nfrom torch.optim import AdamW\nimport numpy as np\nfrom sklearn.metrics import accuracy_score, classification_report, confusion_matrix\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom tqdm.auto import tqdm\nimport warnings\nfrom datasets import load_dataset\nimport os\nimport json\nfrom huggingface_hub import HfApi, login\nimport shap\nwarnings.filterwarnings('ignore')\n\n# Set device - use GPU if available but optimize for memory\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nprint(f\"Using device: {device}\")\n\n# Memory optimization settings\nif torch.cuda.is_available():\n    torch.cuda.empty_cache()\n    try:\n        from torch.cuda.amp import autocast, GradScaler\n        USE_AMP = True\n        scaler = GradScaler()\n    except ImportError:\n        USE_AMP = False\n        print(\"Mixed precision not available, using standard training\")\nelse:\n    USE_AMP = False\n\nclass HC3Dataset(Dataset):\n    \"\"\"Custom dataset class for HC3 data\"\"\"\n    def __init__(self, texts, labels, tokenizer, max_length=256):\n        self.texts = texts\n        self.labels = labels\n        self.tokenizer = tokenizer\n        self.max_length = max_length\n\n    def __len__(self):\n        return len(self.texts)\n\n    def __getitem__(self, idx):\n        text = str(self.texts[idx])\n        label = self.labels[idx]\n        encoding = self.tokenizer(\n            text,\n            truncation=True,\n            padding='max_length',\n            max_length=self.max_length,\n            return_tensors='pt'\n        )\n        return {\n            'input_ids': encoding['input_ids'].flatten(),\n            'attention_mask': encoding['attention_mask'].flatten(),\n            'labels': torch.tensor(label, dtype=torch.long)\n        }\n\nclass AITextDetector:\n    \"\"\"Main class for AI text detection\"\"\"\n    def __init__(self, model_name='distilbert-base-uncased', max_length=256):\n        self.model_name = model_name\n        self.max_length = max_length\n        self.tokenizer = DistilBertTokenizer.from_pretrained(model_name)\n        self.model = None\n        # Initialize BART model and tokenizer for paraphrasing AI-generated text\n        self.paraphrase_model_name = 'facebook/bart-large'\n        try:\n            self.paraphrase_tokenizer = BartTokenizer.from_pretrained(self.paraphrase_model_name)\n            self.paraphrase_model = BartForConditionalGeneration.from_pretrained(self.paraphrase_model_name).to(device)\n            print(f\"Loaded BART paraphrasing model: {self.paraphrase_model_name}\")\n        except Exception as e:\n            print(f\"Error loading BART model for paraphrasing: {e}. Humanized versions will not be generated.\")\n            self.paraphrase_tokenizer = None\n            self.paraphrase_model = None\n\n    def load_hc3_from_huggingface(self, sample_size=5000):\n        \"\"\"Load and preprocess HC3 dataset from Hugging Face\"\"\"\n        print(\"Loading HC3 dataset from Hugging Face...\")\n        try:\n            dataset = load_dataset(\"Hello-SimpleAI/HC3\", name='reddit_eli5', split='train')\n            print(f\"Loaded {len(dataset)} entries from the dataset\")\n\n            if len(dataset) > sample_size:\n                dataset = dataset.shuffle(seed=42).select(range(sample_size))\n            else:\n                dataset = dataset.shuffle(seed=42)\n            print(f\"Using {len(dataset)} entries after sampling\")\n\n            human_texts = []\n            ai_texts = []\n            for item in dataset:\n                if 'human_answers' in item and item['human_answers']:\n                    for answer in item['human_answers']:\n                        if answer and isinstance(answer, str) and len(answer.strip()) > 50:\n                            human_texts.append(answer.strip())\n                if 'chatgpt_answers' in item and item['chatgpt_answers']:\n                    for answer in item['chatgpt_answers']:\n                        if answer and isinstance(answer, str) and len(answer.strip()) > 50:\n                            ai_texts.append(answer.strip())\n\n            min_size = min(len(human_texts), len(ai_texts))\n            if min_size == 0:\n                raise ValueError(\"No valid texts found. Please check your dataset structure.\")\n            max_per_class = min(min_size, sample_size // 2)\n            human_texts = human_texts[:max_per_class]\n            ai_texts = ai_texts[:max_per_class]\n\n            texts = human_texts + ai_texts\n            labels = [0] * len(human_texts) + [1] * len(ai_texts)  # 0: Human, 1: AI\n\n            combined = list(zip(texts, labels))\n            np.random.shuffle(combined)\n            texts, labels = zip(*combined)\n\n            print(f\"Dataset prepared: {len(texts)} samples ({len(human_texts)} human, {len(ai_texts)} AI)\")\n            return list(texts), list(labels)\n        except Exception as e:\n            print(f\"Error loading HC3 dataset: {e}\")\n            raise\n\n    def prepare_data(self, texts, labels, train_ratio=0.8):\n        \"\"\"Split data into train and validation sets\"\"\"\n        split_idx = int(len(texts) * train_ratio)\n        train_texts = texts[:split_idx]\n        train_labels = labels[:split_idx]\n        val_texts = texts[split_idx:]\n        val_labels = labels[split_idx:]\n\n        train_dataset = HC3Dataset(train_texts, train_labels, self.tokenizer, self.max_length)\n        val_dataset = HC3Dataset(val_texts, val_labels, self.tokenizer, self.max_length)\n        return train_dataset, val_dataset\n\n    def train_model(self, train_dataset, val_dataset, epochs=3, batch_size=16, learning_rate=2e-5):\n        \"\"\"Train the classification model with memory optimization\"\"\"\n        print(\"Initializing model...\")\n        self.model = DistilBertForSequenceClassification.from_pretrained(\n            self.model_name,\n            num_labels=2,\n            output_attentions=False,\n            output_hidden_states=False,\n        )\n        self.model.to(device)\n\n        train_loader = DataLoader(\n            train_dataset,\n            batch_size=batch_size,\n            shuffle=True,\n            pin_memory=True if torch.cuda.is_available() else False\n        )\n        val_loader = DataLoader(\n            val_dataset,\n            batch_size=batch_size,\n            shuffle=False,\n            pin_memory=True if torch.cuda.is_available() else False\n        )\n\n        optimizer = AdamW(self.model.parameters(), lr=learning_rate, eps=1e-8)\n        total_steps = len(train_loader) * epochs\n        scheduler = get_linear_schedule_with_warmup(\n            optimizer,\n            num_warmup_steps=0,\n            num_training_steps=total_steps\n        )\n\n        train_losses = []\n        val_accuracies = []\n        print(f\"Starting training for {epochs} epochs...\")\n        for epoch in range(epochs):\n            print(f\"\\nEpoch {epoch + 1}/{epochs}\")\n            self.model.train()\n            total_train_loss = 0\n            progress_bar = tqdm(train_loader, desc=\"Training\")\n            for batch in progress_bar:\n                input_ids = batch['input_ids'].to(device)\n                attention_mask = batch['attention_mask'].to(device)\n                labels = batch['labels'].to(device)\n\n                optimizer.zero_grad()\n\n                if USE_AMP:\n                    with autocast():\n                        outputs = self.model(input_ids=input_ids,\n                                           attention_mask=attention_mask,\n                                           labels=labels)\n                        loss = outputs.loss\n                    scaler.scale(loss).backward()\n                    scaler.step(optimizer)\n                    scaler.update()\n                else:\n                    outputs = self.model(input_ids=input_ids,\n                                       attention_mask=attention_mask,\n                                       labels=labels)\n                    loss = outputs.loss\n                    loss.backward()\n                    optimizer.step()\n\n                scheduler.step()\n                total_train_loss += loss.item()\n                progress_bar.set_postfix({'loss': f'{loss.item():.4f}'})\n\n                if torch.cuda.is_available():\n                    torch.cuda.empty_cache()\n\n            avg_train_loss = total_train_loss / len(train_loader)\n            train_losses.append(avg_train_loss)\n\n            val_accuracy = self.evaluate(val_loader)\n            val_accuracies.append(val_accuracy)\n            print(f\"Average training loss: {avg_train_loss:.4f}\")\n            print(f\"Validation accuracy: {val_accuracy:.4f}\")\n\n        self.plot_training_progress(train_losses, val_accuracies)\n        return train_losses, val_accuracies\n\n    def evaluate(self, val_loader):\n        \"\"\"Evaluate the model\"\"\"\n        self.model.eval()\n        predictions = []\n        true_labels = []\n        with torch.no_grad():\n            for batch in tqdm(val_loader, desc=\"Evaluating\"):\n                input_ids = batch['input_ids'].to(device)\n                attention_mask = batch['attention_mask'].to(device)\n                labels = batch['labels'].to(device)\n                if USE_AMP:\n                    with autocast():\n                        outputs = self.model(input_ids=input_ids, attention_mask=attention_mask)\n                else:\n                    outputs = self.model(input_ids=input_ids, attention_mask=attention_mask)\n                logits = outputs.logits\n                preds = torch.argmax(logits, dim=-1)\n                predictions.extend(preds.cpu().numpy())\n                true_labels.extend(labels.cpu().numpy())\n        accuracy = accuracy_score(true_labels, predictions)\n        return accuracy\n\n    def predict(self, text):\n        \"\"\"Predict whether text is AI-generated or human-written, and provide humanized version if AI-generated\"\"\"\n        if self.model is None:\n            raise ValueError(\"Model not trained yet. Please train the model first.\")\n        self.model.eval()\n        encoding = self.tokenizer(\n            text,\n            truncation=True,\n            padding='max_length',\n            max_length=self.max_length,\n            return_tensors='pt'\n        )\n        input_ids = encoding['input_ids'].to(device)\n        attention_mask = encoding['attention_mask'].to(device)\n        with torch.no_grad():\n            if USE_AMP:\n                with autocast():\n                    outputs = self.model(input_ids=input_ids, attention_mask=attention_mask)\n            else:\n                outputs = self.model(input_ids=input_ids, attention_mask=attention_mask)\n            logits = outputs.logits\n            probabilities = torch.softmax(logits, dim=-1)\n            predicted_class = torch.argmax(logits, dim=-1)\n\n        probs = probabilities.cpu().numpy()[0]\n        pred_class = predicted_class.cpu().numpy()[0]\n\n        confidence = max(probs)\n        label = \"AI-Generated\" if pred_class == 1 else \"Human-Written\"\n\n        result = {\n            'prediction': label,\n            'confidence': confidence,\n            'probabilities': {\n                'human': probs[0],\n                'ai': probs[1]\n            },\n            'humanized_version': None\n        }\n\n        # Generate humanized version if prediction is AI-Generated\n        if label == \"AI-Generated\" and self.paraphrase_model is not None and self.paraphrase_tokenizer is not None:\n            try:\n                paraphrase_inputs = self.paraphrase_tokenizer(\n                    text,\n                    truncation=True,\n                    padding='max_length',\n                    max_length=self.max_length,\n                    return_tensors='pt'\n                ).to(device)\n                with torch.no_grad():\n                    paraphrase_outputs = self.paraphrase_model.generate(\n                        paraphrase_inputs['input_ids'],\n                        attention_mask=paraphrase_inputs['attention_mask'],\n                        max_length=self.max_length,\n                        num_beams=5,\n                        early_stopping=True\n                    )\n                humanized_text = self.paraphrase_tokenizer.decode(paraphrase_outputs[0], skip_special_tokens=True)\n                result['humanized_version'] = humanized_text\n            except Exception as e:\n                print(f\"Error generating humanized version: {e}\")\n                result['humanized_version'] = \"Unable to generate humanized version due to an error.\"\n        elif label == \"AI-Generated\":\n            result['humanized_version'] = \"Paraphrasing model not available.\"\n\n        return result\n\n    def plot_training_progress(self, train_losses, val_accuracies):\n        \"\"\"Plot training progress\"\"\"\n        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))\n        ax1.plot(train_losses, 'b-', label='Training Loss')\n        ax1.set_title('Training Loss')\n        ax1.set_xlabel('Epoch')\n        ax1.set_ylabel('Loss')\n        ax1.legend()\n        ax1.grid(True)\n        ax2.plot(val_accuracies, 'r-', label='Validation Accuracy')\n        ax2.set_title('Validation Accuracy')\n        ax2.set_xlabel('Epoch')\n        ax2.set_ylabel('Accuracy')\n        ax2.legend()\n        ax2.grid(True)\n        plt.tight_layout()\n        plt.show()\n\n    def save_model(self, path):\n        \"\"\"Save the trained model\"\"\"\n        if self.model is None:\n            raise ValueError(\"No model to save. Please train the model first.\")\n        self.model.save_pretrained(path)\n        self.tokenizer.save_pretrained(path)\n        print(f\"Model saved to {path}\")\n\n    def load_model(self, path):\n        \"\"\"Load a pre-trained model\"\"\"\n        self.model = DistilBertForSequenceClassification.from_pretrained(path)\n        self.tokenizer = DistilBertTokenizer.from_pretrained(path)\n        self.model.to(device)\n        print(f\"Model loaded from {path}\")\n\ndef main():\n    \"\"\"Main function to demonstrate the AI text detector\"\"\"\n    print(\"ðŸ¤– AI Text Detection System - HC3 Dataset from Hugging Face\")\n    print(\"=\" * 50)\n\n    detector = AITextDetector()\n\n    texts, labels = detector.load_hc3_from_huggingface(sample_size=3000)\n    train_dataset, val_dataset = detector.prepare_data(texts, labels)\n    print(f\"Training samples: {len(train_dataset)}\")\n    print(f\"Validation samples: {len(val_dataset)}\")\n\n    train_losses, val_accuracies = detector.train_model(\n        train_dataset,\n        val_dataset,\n        epochs=5,\n        batch_size=8,\n        learning_rate=2e-5\n    )\n\n    print(\"\\n\" + \"=\" * 50)\n    print(\"Testing Predictions:\")\n    print(\"=\" * 50)\n    test_texts = [\n        \"Basically there are many categories of \\\" Best Seller \\\" . Replace \\\" Best Seller \\\" by something like \\\" Oscars \\\" and every \\\" best seller \\\" book is basically an \\\" oscar - winning \\\" book . May not have won the \\\" Best film \\\" , but even if you won the best director or best script , you 're still an \\\" oscar - winning \\\" film . Same thing for best sellers . Also , IIRC the rankings change every week or something like that . Some you might not be best seller one week , but you may be the next week . I guess even if you do n't stay there for long , you still achieved the status . Hence , # 1 best seller .\",\n        \"If you 're hearing about it , it 's because it was a very good or very well - publicized book ( or both ) , and almost every good or well - publicized book will be # 1 on the NY Times bestseller list for at least a little bit . Kindof like how almost every big or good movies are # 1 at the box office on their opening weekend .\",\n        \"One reason is lots of catagories . However , how the NY Times calculates its best seller list is n't comprehensive , and is pretty well understood by publishers . So publishers can [ buy a few books ] ( URL_0 ) in the right bookstores and send a book to the top of the list for at least a week .\",\n        \"There are many different best seller lists that are published by various organizations, and the New York Times is just one of them. The New York Times best seller list is a weekly list that ranks the best-selling books in the United States based on sales data from a number of different retailers. The list is published in the New York Times newspaper and is widely considered to be one of the most influential best seller lists in the book industry. It's important to note that the New York Times best seller list is not the only best seller list out there, and there are many other lists that rank the top-selling books in different categories or in different countries. So it's possible that a book could be a best seller on one list but not on another. Additionally, the term \\\"best seller\\\" is often used more broadly to refer to any book that is selling well, regardless of whether it is on a specific best seller list or not. So it's possible that you may hear about a book being a \\\"best seller\\\" even if it is not specifically ranked as a number one best seller on the New York Times list or any other list.\"\n    ]\n\n    for i, text in enumerate(test_texts, 1):\n        result = detector.predict(text)\n        print(f\"\\nTest {i}:\")\n        print(f\"Text: {text[:100]}...\")\n        print(f\"Prediction: {result['prediction']}\")\n        print(f\"Confidence: {result['confidence']:.3f}\")\n        print(f\"Human Probability: {result['probabilities']['human']:.3f}\")\n        print(f\"AI Probability: {result['probabilities']['ai']:.3f}\")\n        if result['humanized_version']:\n            print(f\"Humanized Version: {result['humanized_version'][:100]}...\")\n\n    print(\"\\nSaving model...\")\n    detector.save_model(\"./ai_text_detector_model\")\n    print(\"\\nTraining completed successfully!\")\n    print(\"Model is ready for AI vs Human text classification!\")\n\nif __name__ == \"__main__\":\n    main()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-27T08:52:23.315351Z","iopub.execute_input":"2025-06-27T08:52:23.315680Z","iopub.status.idle":"2025-06-27T08:55:17.568218Z","shell.execute_reply.started":"2025-06-27T08:52:23.315653Z","shell.execute_reply":"2025-06-27T08:55:17.567597Z"}},"outputs":[{"name":"stdout","text":"Using device: cuda\nðŸ¤– AI Text Detection System - HC3 Dataset from Hugging Face\n==================================================\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0447a3f461b34b01985a1c2e78c3de7a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e4d5f1469a2b4abc9e5864b10702ca66"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9d15c5fbd4fd4cd297de47a96d14053c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/483 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e0d9b2afb51d4bda8b00c829c58e8ce7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"422e7d6c78cb4a268e165f2d3c871182"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4c702cc3dec14d7b81fdc9dd56a54793"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"14502ba8c08446c99e43b7ee56683251"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"13a77ef400d2497d9fb39f162921077c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"327e354755374bef96fb7bd70566ae1d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"pytorch_model.bin:   0%|          | 0.00/1.02G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c6d39050b7ff462cb47a1bfda256ffc8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/1.02G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cdc7d0e3c96c4c1599f878e1f3065d31"}},"metadata":{}},{"name":"stdout","text":"Loaded BART paraphrasing model: facebook/bart-large\nLoading HC3 dataset from Hugging Face...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"README.md: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e01aec2dfe674dbdbdb2ede9bba645b1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"HC3.py: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8d0816a6bb524c27b75f0ca0a0eba185"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"0000.parquet:   0%|          | 0.00/30.3M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"66d22220d8fd4994b838eeb20519bea8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/17112 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8f39abe6f4ac41e186eba921daa8aa4c"}},"metadata":{}},{"name":"stdout","text":"Loaded 17112 entries from the dataset\nUsing 3000 entries after sampling\nDataset prepared: 3000 samples (1500 human, 1500 AI)\nTraining samples: 2400\nValidation samples: 600\nInitializing model...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7225c87c9be642578ec3acc0033f339d"}},"metadata":{}},{"name":"stderr","text":"Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"Starting training for 5 epochs...\n\nEpoch 1/5\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/300 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5e8f5ca5111046168897fe4143820e33"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Evaluating:   0%|          | 0/75 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e71e77a5130d4f89a8d09a0e3832e64f"}},"metadata":{}},{"name":"stdout","text":"Average training loss: 0.1386\nValidation accuracy: 0.9617\n\nEpoch 2/5\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/300 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"95d41a6bf137413993183d646070cd0b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Evaluating:   0%|          | 0/75 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"66436c36c5174d98b49d1231026e932f"}},"metadata":{}},{"name":"stdout","text":"Average training loss: 0.0165\nValidation accuracy: 0.9900\n\nEpoch 3/5\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/300 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8713b28c6f1a4005aab5c04ec63cea22"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Evaluating:   0%|          | 0/75 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d6432510393646cb9a6774db9f3a3e52"}},"metadata":{}},{"name":"stdout","text":"Average training loss: 0.0123\nValidation accuracy: 0.9517\n\nEpoch 4/5\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/300 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7e90aed652fb4c6ab572b37df0315d26"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Evaluating:   0%|          | 0/75 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"25564c4bf34c4bf6b5f9229b8de0780a"}},"metadata":{}},{"name":"stdout","text":"Average training loss: 0.0058\nValidation accuracy: 0.9833\n\nEpoch 5/5\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/300 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"23d8c471f1b441abbb3d2bef7144fdc7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Evaluating:   0%|          | 0/75 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c9aa0d4d4d2a40b9bc734f0418f1e275"}},"metadata":{}},{"name":"stdout","text":"Average training loss: 0.0042\nValidation accuracy: 0.9817\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<Figure size 1200x400 with 2 Axes>","image/png":"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\n"},"metadata":{}},{"name":"stdout","text":"\n==================================================\nTesting Predictions:\n==================================================\n\nTest 1:\nText: Basically there are many categories of \" Best Seller \" . Replace \" Best Seller \" by something like \"...\nPrediction: Human-Written\nConfidence: 0.999\nHuman Probability: 0.999\nAI Probability: 0.001\n\nTest 2:\nText: If you 're hearing about it , it 's because it was a very good or very well - publicized book ( or b...\nPrediction: Human-Written\nConfidence: 0.999\nHuman Probability: 0.999\nAI Probability: 0.001\n\nTest 3:\nText: One reason is lots of catagories . However , how the NY Times calculates its best seller list is n't...\nPrediction: Human-Written\nConfidence: 0.999\nHuman Probability: 0.999\nAI Probability: 0.001\n\nTest 4:\nText: There are many different best seller lists that are published by various organizations, and the New ...\nPrediction: AI-Generated\nConfidence: 1.000\nHuman Probability: 0.000\nAI Probability: 1.000\nHumanized Version: There are many different best seller lists that are published by various organizations, and the New ...\n\nSaving model...\nModel saved to ./ai_text_detector_model\n\nTraining completed successfully!\nModel is ready for AI vs Human text classification!\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nfrom transformers import (\n    DistilBertTokenizer, DistilBertForSequenceClassification, \n    BartTokenizer, BartForConditionalGeneration,\n    T5Tokenizer, T5ForConditionalGeneration,\n    pipeline\n)\nfrom sentence_transformers import SentenceTransformer\nimport gradio as gr\nimport shap\nimport faiss\nimport numpy as np\nimport warnings\nimport nltk\nfrom nltk.corpus import wordnet\nimport re\nimport plotly.graph_objects as go\nimport requests\nfrom bs4 import BeautifulSoup\nfrom sklearn.metrics.pairwise import cosine_similarity\nimport json\nimport time\nfrom typing import List, Dict, Tuple, Optional\nwarnings.filterwarnings('ignore')\n\n# Download WordNet for synonyms\ntry:\n    nltk.data.find('corpora/wordnet')\nexcept LookupError:\n    nltk.download('wordnet')\n\n# Set device\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nprint(f\"Using device: {device}\")\n\n# Enhanced dataset for Corrective RAG\nSAMPLE_DATA = [\n    {\"text\": \"Nature has always fascinated me with its intricate beauty and complex ecosystems. The way sunlight filters through forest canopies creates a magical atmosphere that poets and artists have tried to capture for centuries. Walking through a meadow on a spring morning, you can hear the symphony of birds chirping, insects buzzing, and leaves rustling in the gentle breeze.\", \"label\": \"Human-Written\", \"quality\": \"high\"},\n    {\"text\": \"In my experience working with artificial intelligence, I've observed how it transforms industries in unexpected ways. The retail sector, for instance, has embraced AI-powered recommendation systems that understand customer preferences better than ever before. However, the human touch remains irreplaceable when it comes to creativity and emotional intelligence.\", \"label\": \"Human-Written\", \"quality\": \"high\"},\n    {\"text\": \"I remember my grandmother's kitchen vividly - the smell of fresh bread baking, the worn wooden table where we'd sit for hours talking, and the way afternoon light streamed through lace curtains. Those moments taught me that happiness often lies in simple pleasures rather than grand gestures.\", \"label\": \"Human-Written\", \"quality\": \"high\"},\n    {\"text\": \"The rapid advancement of technology has revolutionized the way we communicate and work. Social media platforms have connected people across continents, while remote work tools have made it possible for teams to collaborate seamlessly from different time zones. This digital transformation continues to reshape our daily lives.\", \"label\": \"Human-Written\", \"quality\": \"medium\"},\n    {\"text\": \"Generated by AI, this text describes a futuristic city where robots and humans coexist in perfect harmony. The streets are filled with autonomous vehicles that navigate efficiently through traffic patterns optimized by machine learning algorithms.\", \"label\": \"AI-Generated\", \"quality\": \"low\"},\n    {\"text\": \"This AI-crafted story explores a world of robots who have developed consciousness and seek to understand human emotions. They observe human behavior patterns and attempt to replicate emotional responses through sophisticated programming.\", \"label\": \"AI-Generated\", \"quality\": \"low\"},\n    {\"text\": \"When I think about creativity, I'm reminded of how artists throughout history have pushed boundaries and challenged conventional thinking. From Van Gogh's bold brushstrokes to Beethoven's revolutionary compositions, true innovation comes from those willing to take risks and express their unique vision.\", \"label\": \"Human-Written\", \"quality\": \"high\"},\n    {\"text\": \"Traveling has opened my eyes to different cultures and perspectives that have enriched my understanding of the world. Each destination offers unique flavors, traditions, and stories that remind me of our shared humanity despite surface-level differences.\", \"label\": \"Human-Written\", \"quality\": \"high\"},\n]\n\nclass AgenticRAGRephraser:\n    def __init__(self):\n        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n        \n        # Initialize models with better configurations\n        print(\"Loading models...\")\n        self.bart_tokenizer = BartTokenizer.from_pretrained('facebook/bart-large')\n        self.bart_model = BartForConditionalGeneration.from_pretrained('facebook/bart-large').to(self.device)\n        \n        self.t5_tokenizer = T5Tokenizer.from_pretrained('t5-base')\n        self.t5_model = T5ForConditionalGeneration.from_pretrained('t5-base').to(self.device)\n        \n        self.embedder = SentenceTransformer('all-MiniLM-L6-v2')\n        \n        # Improved agent configuration\n        self.max_iterations = 3\n        self.quality_threshold = 0.75\n        self.relevance_threshold = 0.4\n        self.min_text_length = 20\n        \n        print(\"Agentic RAG Rephraser initialized successfully!\")\n\n    def web_search(self, query: str, num_results: int = 3) -> List[str]:\n        \"\"\"Improved web search with fallback options\"\"\"\n        try:\n            # Clean and format query\n            clean_query = re.sub(r'[^\\w\\s]', '', query).strip()\n            if len(clean_query) < 3:\n                return self._get_fallback_context(query)\n            \n            # Try multiple search approaches\n            results = []\n            \n            # Approach 1: DuckDuckGo\n            try:\n                search_url = f\"https://html.duckduckgo.com/html/?q={clean_query.replace(' ', '+')}\"\n                headers = {\n                    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'\n                }\n                \n                response = requests.get(search_url, headers=headers, timeout=8)\n                if response.status_code == 200:\n                    soup = BeautifulSoup(response.text, 'html.parser')\n                    \n                    # Try different selectors\n                    selectors = [\n                        ('a.result__a', 'div.result__snippet'),\n                        ('h2.result__title a', '.result__snippet'),\n                        ('.result__body', None)\n                    ]\n                    \n                    for title_sel, snippet_sel in selectors:\n                        for result in soup.select(title_sel)[:num_results]:\n                            if snippet_sel:\n                                snippet_div = result.find_next(snippet_sel.replace('.', ''))\n                            else:\n                                snippet_div = result.parent if result.parent else result\n                            \n                            if snippet_div and snippet_div.get_text(strip=True):\n                                text = snippet_div.get_text(strip=True)\n                                cleaned_text = re.sub(r'\\s+', ' ', text)\n                                if 30 < len(cleaned_text) < 500:\n                                    results.append(cleaned_text)\n                        \n                        if results:\n                            break\n            except Exception as e:\n                print(f\"DuckDuckGo search failed: {e}\")\n            \n            # If no results, return fallback context\n            return results if results else self._get_fallback_context(clean_query)\n            \n        except Exception as e:\n            print(f\"Web search error: {e}\")\n            return self._get_fallback_context(query)\n    \n    def _get_fallback_context(self, query: str) -> List[str]:\n        \"\"\"Provide fallback context when web search fails\"\"\"\n        # Style-specific guidance\n        style_contexts = {\n            'formal': [\n                \"Formal writing employs sophisticated vocabulary, complex sentence structures, and maintains an objective tone throughout the discourse.\",\n                \"Academic and professional contexts require precise language, proper transitions, and adherence to conventional grammatical structures.\"\n            ],\n            'casual': [\n                \"Casual writing uses everyday language, contractions, and a conversational tone that feels natural and approachable.\",\n                \"Informal communication often includes personal touches, simpler sentence structures, and relatable expressions.\"\n            ],\n            'academic': [\n                \"Academic writing demands evidence-based arguments, precise terminology, and clear logical progression of ideas.\",\n                \"Scholarly discourse requires proper citations, objective analysis, and adherence to disciplinary conventions.\"\n            ],\n            'professional': [\n                \"Professional communication emphasizes clarity, efficiency, and results-oriented language that drives action.\",\n                \"Business writing focuses on value proposition, strategic thinking, and stakeholder-centered messaging.\"\n            ],\n            'creative': [\n                \"Creative writing explores imaginative expression, vivid imagery, and engaging narrative techniques.\",\n                \"Artistic expression often employs metaphors, varied sentence rhythms, and emotional resonance.\"\n            ],\n            'friendly': [\n                \"Friendly writing feels like chatting with a good friend over coffee, using simple words and a warm, inviting tone.\",\n                \"Conversational writing connects with readers through relatable stories, a touch of humor, and a personal vibe.\"\n            ],\n            'neutral': [\n                \"Neutral writing maintains clarity and balance, avoiding overly emotional or technical language to suit a general audience.\",\n                \"Effective communication in a neutral style focuses on clear ideas and straightforward expression.\"\n            ],\n            'technical': [\n                \"Technical writing prioritizes precision, detailed explanations, and structured formats to convey complex information clearly.\",\n                \"Technical documentation ensures accuracy and usability for specialized audiences.\"\n            ]\n        }\n        \n        # Extract style from query\n        for style, contexts in style_contexts.items():\n            if style in query.lower():\n                return contexts\n        \n        # Default neutral context\n        return [\n            \"Effective writing balances clarity with engagement, ensuring the message resonates with the intended audience.\",\n            \"Good communication adapts tone and structure to match the context and purpose of the text.\"\n        ]\n\n    def extract_key_concepts(self, text: str) -> List[str]:\n        \"\"\"Enhanced concept extraction\"\"\"\n        # Improved stop words list\n        stop_words = {\n            'the', 'a', 'an', 'and', 'or', 'but', 'in', 'on', 'at', 'to', 'for', \n            'of', 'with', 'by', 'is', 'are', 'was', 'were', 'be', 'been', 'have', \n            'has', 'had', 'do', 'does', 'did', 'will', 'would', 'could', 'should',\n            'this', 'that', 'these', 'those', 'i', 'you', 'he', 'she', 'it', 'we', \n            'they', 'them', 'their', 'there', 'where', 'when', 'what', 'how', 'why',\n            'also', 'such', 'than', 'very', 'can', 'may', 'might', 'must', 'shall'\n        }\n        \n        # Extract meaningful words (nouns, adjectives, verbs)\n        words = re.findall(r'\\b[a-zA-Z]{4,}\\b', text.lower())\n        concepts = [word for word in words if word not in stop_words]\n        \n        # Get unique concepts with frequency consideration\n        word_freq = {}\n        for word in concepts:\n            word_freq[word] = word_freq.get(word, 0) + 1\n        \n        # Sort by frequency and importance\n        sorted_concepts = sorted(word_freq.keys(), key=lambda x: word_freq[x], reverse=True)\n        \n        # Extract noun phrases (simple approach)\n        noun_phrases = re.findall(r'\\b[A-Z][a-z]+(?:\\s+[a-z]+){0,2}\\b', text)\n        \n        return sorted_concepts[:6] + [phrase.lower() for phrase in noun_phrases[:2]]\n\n    def retrieve_context(self, text: str, rephrase_style: str) -> Dict:\n        \"\"\"Enhanced context retrieval with better query construction\"\"\"\n        key_concepts = self.extract_key_concepts(text)\n        \n        if not key_concepts:\n            return {\n                'contexts': [],\n                'relevance_score': 0.0,\n                'search_queries': [],\n                'total_results': 0\n            }\n        \n        # Build more targeted search queries\n        search_queries = []\n        \n        # Style-specific query\n        style_query = f\"{rephrase_style} writing style examples\"\n        search_queries.append(style_query)\n        \n        # Content-specific queries\n        if len(key_concepts) >= 2:\n            content_query = f\"{key_concepts[0]} {key_concepts[1]} {rephrase_style}\"\n            search_queries.append(content_query)\n        \n        # Domain-specific query\n        if len(key_concepts) >= 1:\n            domain_query = f\"{key_concepts[0]} professional writing\"\n            search_queries.append(domain_query)\n        \n        # Collect search results\n        all_contexts = []\n        for query in search_queries[:3]:  # Limit to 3 queries\n            contexts = self.web_search(query, num_results=2)\n            all_contexts.extend(contexts)\n        \n        # Filter and rank contexts\n        if all_contexts:\n            try:\n                text_embedding = self.embedder.encode([text])\n                context_embeddings = self.embedder.encode(all_contexts)\n                similarities = cosine_similarity(text_embedding, context_embeddings)[0]\n                \n                # Filter by minimum relevance and sort\n                relevant_contexts = [\n                    (ctx, score) for ctx, score in zip(all_contexts, similarities)\n                    if score > 0.1\n                ]\n                relevant_contexts.sort(key=lambda x: x[1], reverse=True)\n                \n                top_contexts = [ctx for ctx, _ in relevant_contexts[:3]]\n                avg_relevance = np.mean([score for _, score in relevant_contexts[:3]]) if relevant_contexts else 0.0\n            except Exception as e:\n                print(f\"Context ranking error: {e}\")\n                top_contexts = all_contexts[:3]\n                avg_relevance = 0.3\n        else:\n            top_contexts = []\n            avg_relevance = 0.0\n        \n        return {\n            'contexts': top_contexts,\n            'relevance_score': avg_relevance,\n            'search_queries': search_queries,\n            'total_results': len(all_contexts)\n        }\n\n    def evaluate_rephrase_quality(self, original: str, rephrased: str, target_style: str) -> Dict:\n        \"\"\"Enhanced quality evaluation\"\"\"\n        try:\n            # Check for obvious issues\n            if not rephrased or len(rephrased.strip()) < 10:\n                return {'quality_score': 0.0, 'needs_improvement': True, 'error': 'Empty or too short'}\n            \n            if rephrased == original:\n                return {'quality_score': 0.0, 'needs_improvement': True, 'error': 'No change'}\n            \n            # Semantic similarity\n            orig_embedding = self.embedder.encode([original])\n            reph_embedding = self.embedder.encode([rephrased])\n            semantic_similarity = cosine_similarity(orig_embedding, reph_embedding)[0][0]\n            \n            # Length appropriateness\n            orig_words = len(original.split())\n            reph_words = len(rephrased.split())\n            \n            # Penalize extreme length changes\n            if reph_words < orig_words * 0.7 or reph_words > orig_words * 1.5:\n                length_penalty = 0.5\n            else:\n                length_penalty = 1.0\n            \n            # Style consistency (enhanced)\n            style_indicators = {\n                'formal': {\n                    'positive': ['furthermore', 'consequently', 'therefore', 'moreover', 'nevertheless', \n                               'accordingly', 'subsequently', 'thus', 'hence', 'thereby'],\n                    'negative': ['gonna', 'wanna', 'yeah', 'ok', 'cool', 'awesome']\n                },\n                'casual': {\n                    'positive': ['basically', 'pretty much', 'sort of', 'kind of', 'you know', \n                               'like', 'anyway', 'actually', 'really', 'totally'],\n                    'negative': ['furthermore', 'consequently', 'therefore', 'nevertheless']\n                },\n                'academic': {\n                    'positive': ['according to', 'research indicates', 'studies show', 'evidence suggests',\n                               'analysis reveals', 'findings demonstrate', 'data shows'],\n                    'negative': ['i think', 'i believe', 'obviously', 'clearly']\n                },\n                'professional': {\n                    'positive': ['leverage', 'optimize', 'facilitate', 'implement', 'strategic',\n                               'comprehensive', 'initiative', 'framework'],\n                    'negative': ['awesome', 'cool', 'amazing', 'super']\n                },\n                'creative': {\n                    'positive': ['vividly', 'imaginative', 'evocative', 'poetic', 'expressive',\n                               'captivating', 'engaging', 'inspired'],\n                    'negative': ['furthermore', 'consequently', 'therefore']\n                },\n                'friendly': {\n                    'positive': ['hey', 'pretty cool', 'totally', 'like', 'you know', \n                               'awesome', 'fun', 'check this out', 'kinda', 'vibe'],\n                    'negative': ['furthermore', 'consequently', 'therefore', 'hereby']\n                },\n                'neutral': {\n                    'positive': ['clearly', 'effectively', 'generally', 'appropriately', 'consistently'],\n                    'negative': ['gonna', 'wanna', 'awesome', 'super']\n                },\n                'technical': {\n                    'positive': ['specifically', 'precisely', 'technically', 'systematically', 'accurately'],\n                    'negative': ['like', 'you know', 'cool', 'awesome']\n                }\n            }\n            \n            style_score = 0.6  # Default neutral score\n            if target_style.lower() in style_indicators:\n                indicators = style_indicators[target_style.lower()]\n                rephrased_lower = rephrased.lower()\n                \n                positive_count = sum(1 for phrase in indicators['positive'] if phrase in rephrased_lower)\n                negative_count = sum(1 for phrase in indicators['negative'] if phrase in rephrased_lower)\n                \n                style_score = min(1.0, 0.6 + (positive_count * 0.1) - (negative_count * 0.15))\n            \n            # Fluency check (basic)\n            fluency_score = 1.0\n            if len(re.findall(r'\\b\\w+\\b', rephrased)) < 5:\n                fluency_score = 0.5\n            \n            # Overall quality score with weights\n            quality_score = (\n                semantic_similarity * 0.35 + \n                length_penalty * 0.15 + \n                style_score * 0.35 + \n                fluency_score * 0.15\n            )\n            \n            return {\n                'quality_score': quality_score,\n                'semantic_similarity': semantic_similarity,\n                'length_penalty': length_penalty,\n                'style_score': style_score,\n                'fluency_score': fluency_score,\n                'needs_improvement': quality_score < self.quality_threshold\n            }\n            \n        except Exception as e:\n            return {\n                'quality_score': 0.0,\n                'needs_improvement': True,\n                'error': str(e)\n            }\n\n    def generate_rephrase_with_bart(self, text: str, context: str, style: str) -> str:\n        \"\"\"Improved BART rephrasing with better prompting and formatting\"\"\"\n        try:\n            # Clean inputs\n            text = text.strip()\n            context = context.strip() if context else \"\"\n            \n            # Create a more effective prompt with context guidance\n            if context and len(context) > 20:\n                prompt = f\"Using this style guidance: {context[:150]} Rewrite the following text in a {style} style while maintaining paragraph breaks: {text}\"\n            else:\n                prompt = f\"Rewrite the following text in a {style} style while maintaining proper formatting: {text}\"\n            \n            # Tokenize with proper handling\n            inputs = self.bart_tokenizer(\n                prompt,\n                max_length=1024,\n                truncation=True,\n                padding=True,\n                return_tensors='pt'\n            ).to(self.device)\n            \n            # Generate with improved parameters\n            with torch.no_grad():\n                outputs = self.bart_model.generate(\n                    input_ids=inputs['input_ids'],\n                    attention_mask=inputs['attention_mask'],\n                    max_length=min(512, len(text.split()) + 100),\n                    min_length=max(20, len(text.split()) - 20),\n                    num_beams=4,\n                    length_penalty=1.0,\n                    early_stopping=True,\n                    do_sample=True,\n                    temperature=0.7,\n                    no_repeat_ngram_size=3\n                )\n            \n            # Decode and clean\n            rephrased = self.bart_tokenizer.decode(outputs[0], skip_special_tokens=True)\n            \n            # Advanced cleaning to remove prompt artifacts\n            clean_patterns = [\n                r'^.*?style guidance:.*?style:', \n                r'^.*?rewrite.*?style:', \n                r'^.*?following text.*?style:',\n                r'^.*?while maintaining.*?:',\n                r'^Using this.*?:'\n            ]\n            \n            for pattern in clean_patterns:\n                rephrased = re.sub(pattern, '', rephrased, flags=re.IGNORECASE).strip()\n            \n            # Preserve paragraph structure if present in original\n            if '\\n\\n' in text and '\\n' not in rephrased:\n                # Try to restore paragraph breaks based on sentence count\n                sentences = re.split(r'(?<=[.!?])\\s+', rephrased)\n                orig_paragraphs = text.split('\\n\\n')\n                if len(orig_paragraphs) > 1 and len(sentences) > 3:\n                    para_size = len(sentences) // len(orig_paragraphs)\n                    formatted_paras = []\n                    for i in range(0, len(sentences), para_size):\n                        para_sentences = sentences[i:i+para_size]\n                        formatted_paras.append(' '.join(para_sentences))\n                    rephrased = '\\n\\n'.join(formatted_paras)\n            \n            return rephrased if rephrased and len(rephrased) > 10 else text\n            \n        except Exception as e:\n            print(f\"BART generation error: {e}\")\n            return text\n\n    def generate_rephrase_with_t5(self, text: str, context: str, style: str) -> str:\n        \"\"\"Improved T5 rephrasing\"\"\"\n        try:\n            # T5 works better with specific task instructions\n            prompt = f\"paraphrase: Make this text more {style}: {text}\"\n            \n            inputs = self.t5_tokenizer(\n                prompt,\n                max_length=512,\n                truncation=True,\n                padding=True,\n                return_tensors='pt'\n            ).to(self.device)\n            \n            with torch.no_grad():\n                outputs = self.t5_model.generate(\n                    input_ids=inputs['input_ids'],\n                    attention_mask=inputs['attention_mask'],\n                    max_length=min(256, len(text.split()) * 2),\n                    min_length=max(10, len(text.split()) // 2),\n                    num_beams=3,\n                    length_penalty=1.0,\n                    early_stopping=True,\n                    do_sample=False,\n                    no_repeat_ngram_size=2\n                )\n            \n            rephrased = self.t5_tokenizer.decode(outputs[0], skip_special_tokens=True)\n            \n            return rephrased if rephrased and len(rephrased) > 10 else text\n            \n        except Exception as e:\n            print(f\"T5 generation error: {e}\")\n            return text\n\n    def agentic_rephrase(self, text: str, style: str = \"neutral\") -> Dict:\n        \"\"\"Enhanced agentic rephrasing with better error handling\"\"\"\n        # Input validation\n        if not text or len(text.strip()) < self.min_text_length:\n            return {\n                'final_text': text,\n                'iterations': 0,\n                'agent_log': [\"Error: Text too short (minimum 20 characters required)\"],\n                'context_used': [],\n                'quality_scores': [],\n                'final_score': 0.0\n            }\n        \n        text = text.strip()\n        agent_log = []\n        iterations = 0\n        current_text = text\n        best_text = text\n        best_score = 0.0\n        quality_scores = []\n        contexts_used = []\n        \n        agent_log.append(f\"ðŸ¤– Agent initialized for '{style}' style rephrasing\")\n        agent_log.append(f\"ðŸ“ Input length: {len(text)} characters, {len(text.split())} words\")\n        \n        for iteration in range(self.max_iterations):\n            iterations += 1\n            agent_log.append(f\"\\n--- Iteration {iteration + 1} ---\")\n            \n            # Step 1: Retrieve context\n            agent_log.append(\"ðŸ” Retrieving context...\")\n            context_result = self.retrieve_context(current_text, style)\n            \n            if context_result['contexts']:\n                contexts_used.extend(context_result['contexts'][:2])\n                agent_log.append(f\"âœ… Found {len(context_result['contexts'])} relevant contexts\")\n                agent_log.append(f\"ðŸ“Š Context relevance: {context_result['relevance_score']:.3f}\")\n            else:\n                # Use fallback context for style guidance\n                fallback_contexts = self._get_fallback_context(style)\n                context_result['contexts'] = fallback_contexts\n                contexts_used.extend(fallback_contexts[:1])\n                agent_log.append(\"ðŸ’¡ Using fallback style guidance context\")\n                agent_log.append(f\"ðŸ“š Fallback contexts: {len(fallback_contexts)}\")\n            \n            # Step 2: Generate candidates\n            agent_log.append(\"âœï¸ Generating rephrase candidates...\")\n            \n            main_context = \" \".join(context_result['contexts'][:2]) if context_result['contexts'] else \"\"\n            \n            candidates = []\n            \n            # Generate with BART\n            bart_candidate = self.generate_rephrase_with_bart(current_text, main_context, style)\n            if bart_candidate != current_text:\n                candidates.append((\"BART\", bart_candidate))\n            \n            # Generate with T5\n            t5_candidate = self.generate_rephrase_with_t5(current_text, main_context, style)\n            if t5_candidate != current_text:\n                candidates.append((\"T5\", t5_candidate))\n            \n            agent_log.append(f\"ðŸ“ Generated {len(candidates)} valid candidates\")\n            \n            if not candidates:\n                agent_log.append(\"âš ï¸ No valid candidates generated\")\n                break\n            \n            # Step 3: Evaluate candidates\n            agent_log.append(\"ðŸŽ¯ Evaluating candidates...\")\n            best_candidate = current_text\n            best_candidate_score = best_score\n            \n            for model_name, candidate in candidates:\n                quality = self.evaluate_rephrase_quality(text, candidate, style)\n                \n                if 'error' not in quality:\n                    quality_scores.append(quality['quality_score'])\n                    agent_log.append(f\"  {model_name}: Quality={quality['quality_score']:.3f}, Semantic={quality['semantic_similarity']:.3f}\")\n                    \n                    if quality['quality_score'] > best_candidate_score:\n                        best_candidate = candidate\n                        best_candidate_score = quality['quality_score']\n                else:\n                    agent_log.append(f\"  {model_name}: Failed - {quality['error']}\")\n            \n            # Step 4: Update best result\n            if best_candidate_score > best_score:\n                best_text = best_candidate\n                best_score = best_candidate_score\n                current_text = best_candidate\n                agent_log.append(f\"âœ… Improvement found! New score: {best_score:.3f}\")\n                \n                # Check if we've reached the quality threshold\n                if best_score >= self.quality_threshold:\n                    agent_log.append(f\"ðŸŽ‰ Quality threshold ({self.quality_threshold}) reached!\")\n                    break\n            else:\n                agent_log.append(\"âž¡ï¸ No improvement this iteration\")\n        \n        # Final summary\n        agent_log.append(f\"\\nðŸ Final Results:\")\n        agent_log.append(f\"   â€¢ Best Quality Score: {best_score:.3f}\")\n        agent_log.append(f\"   â€¢ Total Iterations: {iterations}\")\n        agent_log.append(f\"   â€¢ Contexts Used: {len(contexts_used)}\")\n        \n        return {\n            'final_text': best_text,\n            'iterations': iterations,\n            'agent_log': agent_log,\n            'context_used': contexts_used,\n            'quality_scores': quality_scores,\n            'final_score': best_score\n        }\n\nclass AITextDetector:\n    def __init__(self, model_name='distilbert-base-uncased', max_length=256):\n        self.model_name = model_name\n        self.max_length = max_length\n        self.tokenizer = DistilBertTokenizer.from_pretrained(model_name)\n        self.model = None\n        self.sentiment_tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased-finetuned-sst-2-english')\n        self.sentiment_model = DistilBertForSequenceClassification.from_pretrained('distilbert-base-uncased-finetuned-sst-2-english').to(device)\n        self.embedder = SentenceTransformer('all-MiniLM-L6-v2')\n        self.faiss_index = None\n        self.dataset_texts = [item[\"text\"] for item in SAMPLE_DATA]\n        self.dataset_labels = [item[\"label\"] for item in SAMPLE_DATA]\n        self.dataset_quality = [item[\"quality\"] for item in SAMPLE_DATA]\n        self.relevance_threshold = 0.75\n        self.paraphrase_tokenizer = BartTokenizer.from_pretrained('facebook/bart-base')\n        self.paraphrase_model = BartForConditionalGeneration.from_pretrained('facebook/bart-base').to(device)\n        self.agentic_rephraser = AgenticRAGRephraser()\n        self.build_faiss_index()\n\n    def build_faiss_index(self):\n        embeddings = self.embedder.encode(self.dataset_texts, convert_to_numpy=True)\n        dimension = embeddings.shape[1]\n        self.faiss_index = faiss.IndexFlatL2(dimension)\n        self.faiss_index.add(embeddings)\n\n    def evaluate_retrieval_quality(self, query_text, retrieved_texts):\n        query_embedding = self.embedder.encode([query_text])\n        retrieved_embeddings = self.embedder.encode(retrieved_texts)\n        similarities = cosine_similarity(query_embedding, retrieved_embeddings)[0]\n        avg_similarity = np.mean(similarities) if len(similarities) > 0 else 0.0\n        if avg_similarity >= self.relevance_threshold:\n            return \"correct\", similarities, avg_similarity\n        elif avg_similarity >= (self.relevance_threshold - 0.2):\n            return \"ambiguous\", similarities, avg_similarity\n        else:\n            return \"incorrect\", similarities, avg_similarity\n\n    def corrective_retrieval(self, text, k=3):\n        query_embedding = self.embedder.encode([text], convert_to_numpy=True)\n        distances, indices = self.faiss_index.search(query_embedding, k * 2)\n        initial_context = [self.dataset_texts[idx] for idx in indices[0][:k]]\n        initial_qualities = [self.dataset_quality[idx] for idx in indices[0][:k]]\n        retrieval_status, similarities, avg_similarity = self.evaluate_retrieval_quality(text, initial_context)\n        corrective_log = []\n        final_context = initial_context\n        if retrieval_status == \"correct\":\n            high_quality_context = [ctx for i, ctx in enumerate(initial_context) if initial_qualities[i] == \"high\" and self.dataset_labels[indices[0][i]] == \"Human-Written\"]\n            final_context = high_quality_context[:k] if high_quality_context else initial_context\n            corrective_log.append(\"âœ“ High-quality human examples selected\" if high_quality_context else \"âœ“ Standard retrieval\")\n        elif retrieval_status == \"ambiguous\":\n            human_written_indices = [i for i, idx in enumerate(indices[0]) if self.dataset_labels[idx] == \"Human-Written\"]\n            final_context = [self.dataset_texts[indices[0][i]] for i in human_written_indices[:k]] if human_written_indices else initial_context\n            corrective_log.append(\"âš  Ambiguous retrieval - refined with human examples\" if human_written_indices else \"âš  Ambiguous retrieval\")\n        else:\n            corrective_log.append(\"âœ— Low-quality retrieval - applying corrections\")\n            human_high_quality_indices = [i for i, idx in enumerate(indices[0]) if self.dataset_labels[idx] == \"Human-Written\" and self.dataset_quality[idx] == \"high\"]\n            if human_high_quality_indices:\n                final_context = [self.dataset_texts[idx] for idx in human_high_quality_indices[:k]]\n                corrective_log.append(\"â†’ Correction applied: High-quality human examples\")\n            else:\n                keywords = self.extract_key_concepts(text)\n                keyword_matched_context = [t for i, t in enumerate(self.dataset_texts) if self.dataset_labels[i] == \"Human-Written\" and any(k in t.lower() for k in keywords)]\n                final_context = keyword_matched_context[:k] if keyword_matched_context else self.get_humanization_templates()[:k]\n                corrective_log.append(\"â†’ Correction applied: Keyword-based\" if keyword_matched_context else \"â†’ Correction applied: Templates\")\n        return {\n            'context': final_context,\n            'retrieval_status': retrieval_status,\n            'avg_similarity': avg_similarity,\n            'similarities': similarities.tolist() if len(similarities) > 0 else [],\n            'corrective_log': corrective_log\n        }\n\n    def extract_key_concepts(self, text):\n        words = re.findall(r'\\b[a-zA-Z]{4,}\\b', text.lower())\n        stop_words = {'that', 'this', 'with', 'have', 'will', 'from', 'they', 'been', 'were', 'said', 'each', 'which', 'their', 'time', 'would', 'there', 'could', 'other'}\n        return list(set([word for word in words if word not in stop_words]))[:5]\n\n    def get_synonyms(self, word):\n        synonyms = set()\n        for syn in wordnet.synsets(word.lower()):\n            for lemma in syn.lemmas():\n                synonym = lemma.name().replace('_', ' ')\n                if synonym.lower() != word.lower() and len(synonym) > 1:\n                    synonyms.add(synonym)\n        preferred_synonyms = {\n            'human being': 'human',\n            'organisation': 'system',\n            'advocate': 'recommend',\n            'twist around': 'manage',\n            'call for': 'require',\n            'acquire': 'learn',\n            'trouble': 'problem',\n            'corresponding': 'like',\n            'prompt': 'inspired',\n            'homo': 'human',\n            'forward motion': 'progress',\n            'singular': 'unique',\n            'breakthrough': 'advancement',\n            'push': 'driving',\n            'realism': 'reality',\n            'calculator': 'computer',\n            'truth': 'accuracy',\n            'individualised': 'personalized',\n            'contrive': 'plan',\n            'oblation': 'offering',\n            'antecedently': 'previously',\n            'business enterprise': 'business',\n            'prognosticative': 'predictive',\n            'excogitation': 'innovation',\n            'nonetheless': 'however',\n            'likewise': 'also',\n            'off': 'raise',\n            'honorable': 'ethical',\n            'considerateness': 'consideration',\n            'interrogative sentence': 'question',\n            'requirement': 'need',\n            'thrifty': 'careful',\n            'aid': 'attention',\n            'secure': 'ensure',\n            'align': 'aligns',\n            'lodge': 'society',\n            'overriding': 'critical',\n            'desegregate': 'integrate',\n            'sprightliness': 'lives',\n            'poise': 'balanced',\n            'of the essence': 'essential',\n            'mankind': 'humanity'\n        }\n        synonyms = list(synonyms)[:5]\n        return [preferred_synonyms.get(word.lower(), word) for word in synonyms] if synonyms else []\n\n    def get_humanization_templates(self):\n        return [\n            \"In my view, sharing personal stories makes writing feel alive. I recall moments that shaped my perspective, like quiet evenings with family discussing life's simple joys.\",\n            \"I've always found that writing with emotion connects deeply. It's like telling a friend about a meaningful experience over a warm cup of coffee.\",\n            \"From my perspective, authentic writing reflects real-life moments. It's those little details, like a familiar scent or a fleeting glance, that make stories resonate.\"\n        ]\n\n    def humanize_text(self, text, k=3):\n        if not text or len(text.strip().split()) < 10:\n            return {\n                'enhanced_text': text,\n                'original_text': text,\n                'context': [],\n                'changed_words': [],\n                'status': 'error: Text too short or empty',\n                'retrieval_status': 'none',\n                'avg_similarity': 0.0,\n                'similarities': [],\n                'corrective_log': []\n            }\n        try:\n            crag_result = self.corrective_retrieval(text, k=k)\n            sentences = re.split(r'(?<=[.!?])\\s+', text.strip())\n            key_points = [{'sentence': s.strip(), 'keywords': self.extract_key_concepts(s)} for s in sentences if s.strip()]\n            changed_words = []\n            humanized_sentences = []\n            used_cues = []\n            for point in key_points:\n                sentence = point['sentence']\n                paraphrased = sentence\n                for keyword in point['keywords']:\n                    if keyword not in {'that', 'this', 'with', 'have', 'will', 'from', 'they', 'been', 'were', 'said', 'each', 'which', 'their', 'time', 'would', 'there', 'could', 'other'}:\n                        synonyms = self.get_synonyms(keyword)\n                        if synonyms:\n                            new_word = np.random.choice(synonyms)\n                            paraphrased = self.replace_word_in_text(paraphrased, keyword, new_word)\n                            changed_words.append((keyword, new_word))\n                cues = ['In my view', \"I've noticed\", 'It reminds me', 'From my perspective', 'Honestly', 'It strikes me', 'As I see it']\n                available_cues = [cue for cue in cues if cue not in used_cues]\n                if available_cues and not any(cue.lower() in paraphrased.lower() for cue in cues) and np.random.random() < 0.3:\n                    cue = np.random.choice(available_cues)\n                    used_cues.append(cue)\n                    paraphrased = f\"{cue}, {paraphrased[0].lower() + paraphrased[1:]}\"\n                if len(paraphrased.split()) > 10:\n                    words = paraphrased.split()\n                    mid = len(words) // 2\n                    connectors = ['Plus', 'Also', \"\"\"What's more\"\"\", 'On top of that']\n                    if np.random.random() < 0.2:\n                        paraphrased = f\"{' '.join(words[:mid])}. {np.random.choice(connectors)}, {' '.join(words[mid:])}\"\n                humanized_sentences.append(paraphrased)\n            if crag_result['context']:\n                context_keywords = self.extract_key_concepts(np.random.choice(crag_result['context']))\n                reflection = f\"Thinking about it, {context_keywords[0] if context_keywords else 'this topic'} feels personal, like moments that have shaped my own experiences.\"\n                humanized_sentences.append(reflection)\n            humanized_text = '. '.join(s.strip().capitalize() for s in humanized_sentences if s.strip())\n            original_word_count = len(text.split())\n            humanized_word_count = len(re.sub(r'<b>|</b>', '', humanized_text).split())\n            if humanized_word_count < original_word_count * 0.8:\n                humanized_text += f\". To me, these ideas resonate like conversations with close friends, full of warmth and meaning.\"\n            clean_humanized_text = re.sub(r'<b>|</b>', '', humanized_text)\n            status_output = f\"Status: {crag_result['retrieval_status'].upper()}\\nðŸ“Š Avg Similarity: {crag_result['avg_similarity']:.3f}\\nðŸ”„ Actions:\\n\"\n            for log in crag_result['corrective_log']:\n                status_output += f\"   â€¢ {log}\\n\"\n            return {\n                'enhanced_text': clean_humanized_text,\n                'original_text': text,\n                'context': crag_result['context'],\n                'changed_words': changed_words,\n                'status': 'success',\n                'retrieval_status': crag_result['retrieval_status'],\n                'avg_similarity': crag_result['avg_similarity'],\n                'similarities': crag_result['similarities'],\n                'corrective_log': crag_result['corrective_log']\n            }\n        except Exception as e:\n            return {\n                'enhanced_text': text,\n                'original_text': text,\n                'context': [],\n                'changed_words': [],\n                'status': f'error: {str(e)}',\n                'retrieval_status': 'none',\n                'avg_similarity': 0.0,\n                'similarities': [],\n                'corrective_log': [f\"Error: {str(e)}\"]\n            }\n\n    def replace_word_in_text(self, text, old_word, new_word):\n        if not new_word or not old_word:\n            return text\n        pattern = r'\\b' + re.escape(old_word) + r'\\b'\n        def preserve_case(match):\n            orig = match.group(0)\n            if orig.isupper():\n                return f\"<b>{new_word.upper()}</b>\"\n            elif orig[0].isupper():\n                return f\"<b>{new_word.capitalize()}</b>\"\n            return f\"<b>{new_word.lower()}</b>\"\n        return re.sub(pattern, preserve_case, text, flags=re.IGNORECASE)\n\n    def predict(self, text, confidence_threshold=0.8, max_iterations=3):\n        if self.model is None:\n            raise ValueError(\"Model not trained or loaded. Please load the model first.\")\n        self.model.eval()\n        encoding = self.tokenizer(\n            text,\n            truncation=True,\n            padding='max_length',\n            max_length=self.max_length,\n            return_tensors='pt'\n        )\n        input_ids = encoding['input_ids'].to(device)\n        attention_mask = encoding['attention_mask'].to(device)\n        with torch.no_grad():\n            outputs = self.model(input_ids=input_ids, attention_mask=attention_mask)\n            logits = outputs.logits\n            probabilities = torch.softmax(logits, dim=-1)\n            predicted_class = torch.argmax(logits, dim=-1)\n        probs = probabilities.cpu().numpy()[0]\n        pred_class = predicted_class.cpu().numpy()[0]\n        confidence = max(probs)\n        label = \"AI-Generated\" if pred_class == 1 else \"Human-Written\"\n        result = {\n            'prediction': label,\n            'confidence': confidence,\n            'probabilities': {'human': probs[0], 'ai': probs[1]},\n            'text': text,\n            'react_log': \"\"\n        }\n        if confidence < confidence_threshold and max_iterations > 0:\n            print(f\"Low confidence ({confidence:.3f}). Initiating ReAct loop...\")\n            shap_values = self.get_shap_values(text)\n            high_impact_word = self.get_high_impact_word(shap_values, text, label)\n            if high_impact_word:\n                synonyms = self.get_synonyms(high_impact_word)\n                if synonyms:\n                    new_word = synonyms[0]\n                    new_text = self.replace_word_in_text(text, high_impact_word, new_word)\n                    print(f\"ReAct: Replaced '{high_impact_word}' with '{new_word}'\")\n                    next_result = self.predict(new_text, confidence_threshold, max_iterations-1)\n                    result = {\n                        'prediction': next_result['prediction'],\n                        'confidence': next_result['confidence'],\n                        'probabilities': next_result['probabilities'],\n                        'text': next_result['text'],\n                        'react_log': f\"ReAct: Replaced '{high_impact_word}' with '{new_word}'. New prediction: {next_result['prediction']}\"\n                    }\n        return result\n\n    def get_shap_values(self, text):\n        classifier = pipeline(\n            \"text-classification\",\n            model=self.model,\n            tokenizer=self.tokenizer,\n            device=0 if torch.cuda.is_available() else -1,\n            top_k=None\n        )\n        explainer = shap.Explainer(classifier)\n        return explainer([text])\n\n    def get_high_impact_word(self, shap_values, text, prediction_label):\n        predicted_class_idx = 1 if prediction_label == \"AI-Generated\" else 0\n        shap_values_for_class = shap_values[0][:, predicted_class_idx]\n        tokens = shap_values.data[0]\n        word_contributions = []\n        current_word = \"\"\n        current_score = 0\n        for token, value in zip(tokens, shap_values_for_class.values):\n            if token.startswith(\"##\"):\n                current_word += token[2:]\n                current_score += value\n            else:\n                if current_word:\n                    word_contributions.append((current_word, current_score))\n                current_word = token\n                current_score = value\n        if current_word:\n            word_contributions.append((current_word, current_score))\n        if word_contributions:\n            top_word = max(word_contributions, key=lambda x: abs(x[1]))[0]\n            return top_word if top_word in extract_words_from_text(text) else None\n        return None\n\n    def load_model(self, path):\n        try:\n            self.model = DistilBertForSequenceClassification.from_pretrained(path)\n            self.tokenizer = DistilBertTokenizer.from_pretrained(path)\n            self.model.to(device)\n            print(f\"Model loaded from {path}\")\n        except Exception as e:\n            print(f\"Error loading model: {e}. Using default model: {self.model_name}\")\n            self.model = DistilBertForSequenceClassification.from_pretrained(self.model_name)\n            self.tokenizer = DistilBertTokenizer.from_pretrained(self.model_name)\n            self.model.to(device)\n\n    def fetch_web_context(self, query, num_results=3):\n        try:\n            search_url = f\"https://html.duckduckgo.com/html/?q={query.replace(' ', '+')}+synonym+definition\"\n            headers = {'User-Agent': 'Mozilla/5.0'}\n            response = requests.get(search_url, headers=headers, timeout=10)\n            response.raise_for_status()\n            soup = BeautifulSoup(response.text, 'html.parser')\n            snippets = []\n            for result in soup.find_all('a', class_='result__a', limit=num_results):\n                snippet = result.find_next('div', class_='result__snippet')\n                if snippet and snippet.text.strip():\n                    snippets.append(snippet.text.strip())\n            if not snippets:\n                snippets = [f\"Context for {query} is limited; consider synonyms like variations of the word.\"]\n            return snippets\n        except Exception as e:\n            return [f\"Default context for {query}: No web data available; try a common word.\"]\n\n    def generate_prompted_synonyms(self, word, text):\n        if not word or not text:\n            return [\"No synonyms found\"], \"Invalid input.\"\n        try:\n            word = word.strip().lower()\n            context = self.fetch_web_context(word)\n            context_text = \" \".join(context) if context else text[:150]\n            prompt = (\n                f\"Generate exactly 5 synonyms for the word '{word}' that match the tone and context of the text: '{text[:100]}...'. \"\n                f\"Use the context: '{context_text[:150]}...'. Return only the synonyms, separated by commas.\"\n            )\n            inputs = self.paraphrase_tokenizer(\n                prompt,\n                truncation=True,\n                padding='max_length',\n                max_length=100,\n                return_tensors='pt'\n            ).to(device)\n            with torch.no_grad():\n                outputs = self.paraphrase_model.generate(\n                    input_ids=inputs['input_ids'],\n                    attention_mask=inputs['attention_mask'],\n                    max_length=50,\n                    num_beams=5,\n                    num_return_sequences=1,\n                    early_stopping=True\n                )\n            generated_text = self.paraphrase_tokenizer.decode(outputs[0], skip_special_tokens=True)\n            synonyms = [s.strip() for s in re.split(r'[,;]\\s*', generated_text) if s.strip() and len(s.strip()) > 1]\n            synonyms = list(dict.fromkeys(synonyms))[:5]\n            if len(synonyms) < 5:\n                wordnet_syns = self.get_synonyms(word)\n                synonyms.extend(wordnet_syns[:5 - len(synonyms)])\n            return synonyms[:5], \"Synonyms generated successfully.\"\n        except Exception as e:\n            wordnet_syns = self.get_synonyms(word)\n            return wordnet_syns[:5] if wordnet_syns else [\"No synonyms found\"], f\"Error: {str(e)}\"\n\n    def analyze_sentiment(self, text):\n        if not text or not self.sentiment_model:\n            return {\"sentiment\": \"error: No text or model unavailable\", \"confidence\": 0.0}\n        try:\n            self.sentiment_model.to(device)\n            sentiment_pipeline = pipeline(\n                \"sentiment-analysis\",\n                model=self.sentiment_model,\n                tokenizer=self.sentiment_tokenizer,\n                device=0 if torch.cuda.is_available() else -1\n            )\n            result = sentiment_pipeline(text)[0]\n            sentiment = result['label'].lower()\n            if sentiment == \"positive\":\n                sentiment = \"positive\"\n            elif sentiment == \"negative\":\n                sentiment = \"negative\"\n            else:\n                sentiment = \"neutral\"\n            confidence = result['score']\n            return {\"sentiment\": sentiment, \"confidence\": confidence}\n        except Exception as e:\n            return {\"sentiment\": f\"error: {str(e)}\", \"confidence\": 0.0}\n\n    def agentic_rephrase_text(self, text, style=\"neutral\"):\n        if not text or len(text.strip()) < 20:\n            return {\n                'final_text': text,\n                'agent_log': [\"Error: Text too short (minimum 20 characters required)\"],\n                'context_used': [],\n                'stats': \"No processing done\"\n            }\n        try:\n            result = self.agentic_rephraser.agentic_rephrase(text, style)\n            agent_log_text = \"\\n\".join(result['agent_log'])\n            context_text = \"Retrieved Context:\\n\\n\"\n            if result['context_used']:\n                for i, ctx in enumerate(result['context_used'], 1):\n                    context_text += f\"{i}. {ctx[:200]}{'...' if len(ctx) > 200 else ''}\\n\\n\"\n            else:\n                context_text += \"No relevant context retrieved from web search.\\n\"\n            stats_text = f\"\"\"Rephrasing Statistics:\nâ€¢ Iterations: {result['iterations']}\nâ€¢ Final Quality Score: {result['final_score']:.3f}\nâ€¢ Quality Threshold: {self.agentic_rephraser.quality_threshold}\nâ€¢ Quality Scores: {[f\"{score:.3f}\" for score in result['quality_scores']]}\nâ€¢ Context Sources: {len(result['context_used'])}\nâ€¢ Status: {'Threshold Reached' if result['final_score'] >= self.agentic_rephraser.quality_threshold else 'Below Threshold'}\"\"\"\n            return {\n                'final_text': result['final_text'],\n                'agent_log': agent_log_text,\n                'context_used': context_text,\n                'stats': stats_text\n            }\n        except Exception as e:\n            return {\n                'final_text': text,\n                'agent_log': f\"Error during rephrasing: {str(e)}\",\n                'context_used': \"\",\n                'stats': \"Error occurred\"\n            }\n\ndef extract_words_from_text(text):\n    words = re.findall(r'\\b[a-zA-Z]+\\b', text)\n    seen = set()\n    unique_words = []\n    for word in words:\n        word_lower = word.lower()\n        if word_lower not in seen and len(word) > 2:\n            seen.add(word_lower)\n            unique_words.append(word)\n    return unique_words\n\ndef create_shap_bar_chart(shap_values, text, prediction_label):\n    predicted_class_idx = 1 if prediction_label == \"AI-Generated\" else 0\n    shap_values_for_class = shap_values[0][:, predicted_class_idx]\n    tokens = shap_values.data[0]\n    word_contributions = []\n    current_word = \"\"\n    current_score = 0\n    for token, value in zip(tokens, shap_values_for_class.values):\n        if token.startswith(\"##\"):\n            current_word += token[2:]\n            current_score += value\n        else:\n            if current_word:\n                word_contributions.append((current_word, current_score))\n            current_word = token\n            current_score = value\n    if current_word:\n        word_contributions.append((current_word, current_score))\n    top_words = sorted(word_contributions, key=lambda x: abs(x[1]), reverse=True)[:10]\n    words, scores = zip(*top_words) if top_words else ([], [])\n    colors = ['red' if score > 0 and prediction_label == \"AI-Generated\" else 'blue' for score in scores]\n    fig = go.Figure(data=[\n        go.Bar(\n            y=words,\n            x=scores,\n            orientation='h',\n            marker_color=colors,\n            text=[f\"{score:.3f}\" for score in scores],\n            textposition='auto',\n        )\n    ])\n    fig.update_layout(\n        title=f\"Top 10 Tokens Influencing {prediction_label} Prediction\",\n        xaxis_title=\"SHAP Value (Impact on Prediction)\",\n        yaxis_title=\"Tokens\",\n        yaxis=dict(autorange=\"reversed\"),\n        showlegend=False,\n        height=400,\n        margin=dict(l=100, r=20, t=50, b=50)\n    )\n    return fig\n\ndef classify_text(text):\n    if text.strip().lower() == 'quit':\n        return \"Classifier stopped.\", None, [], \"\"\n    word_count = len(text.strip().split())\n    if word_count < 80:\n        return f\"Input must be at least 80 words (current: {word_count}).\", None, [], \"\"\n    try:\n        detector = AITextDetector()\n        model_path = './ai_text_detector_model'\n        detector.load_model(model_path)\n        result = detector.predict(text)\n        prediction_output = (\n            f\"Prediction: {result['prediction']}\\n\"\n            f\"Confidence: {result['confidence']:.3f}\\n\"\n            f\"Human Probability: {result['probabilities']['human']:.3f}\\n\"\n            f\"AI Probability: {result['probabilities']['ai']:.3f}\\n\"\n        )\n        if result['react_log']:\n            prediction_output += f\"\\nReAct Log: {result['react_log']}\"\n        classifier = pipeline(\n            \"text-classification\",\n            model=detector.model,\n            tokenizer=detector.tokenizer,\n            device=0 if torch.cuda.is_available() else -1,\n            top_k=None\n        )\n        explainer = shap.Explainer(classifier)\n        shap_values = explainer([text])\n        shap_plot = create_shap_bar_chart(shap_values, text, result['prediction'])\n        words = extract_words_from_text(text)\n        return prediction_output, shap_plot, words, text\n    except Exception as e:\n        return f\"Error: {e}\", None, [], text\n\ndef humanize_text_function(text):\n    if not text or not text.strip():\n        return \"No text to humanize.\", \"\", \"\", []\n    word_count = len(text.strip().split())\n    if word_count < 10:\n        return f\"Text too short for humanization (current: {word_count} words).\", text, \"\", []\n    try:\n        detector = AITextDetector()\n        humanize_result = detector.humanize_text(text, k=3)\n        if humanize_result['status'] == 'success':\n            context_output = \"Retrieved Context for Humanization:\\n\\n\"\n            similarities = humanize_result.get('similarities', [])\n            for i, ctx in enumerate(humanize_result['context'], 1):\n                sim = similarities[i-1] if i-1 < len(similarities) else 0.0\n                context_output += f\"Context {i} (Similarity: {sim:.3f}): {ctx}\\n\\n\"\n            return (\n                f\"Status: {humanize_result['retrieval_status'].upper()}\\nAvg Similarity: {humanize_result['avg_similarity']:.3f}\",\n                humanize_result['enhanced_text'],\n                context_output,\n                humanize_result['changed_words']\n            )\n        else:\n            return (\n                f\"Humanization failed: {humanize_result['status']}\",\n                text,\n                \"\",\n                []\n            )\n    except Exception as e:\n        return f\"Error during humanization: {e}\", text, \"\", []\n\ndef agentic_rephrase_function(text, style):\n    if not text or not text.strip():\n        return \"Please enter text to rephrase.\", \"\", \"\", \"\"\n    if len(text.strip()) < 20:\n        return \"Text too short. Please enter at least 20 characters.\", \"\", \"\", \"\"\n    try:\n        detector = AITextDetector()\n        result = detector.agentic_rephrase_text(text, style)\n        return result['final_text'], result['agent_log'], result['context_used'], result['stats']\n    except Exception as e:\n        error_msg = f\"Error during rephrasing: {str(e)}\"\n        return error_msg, error_msg, \"\", \"\"\n\ncustom_css = \"\"\"\n.gradio-container {\n    max-width: 1200px !important;\n}\n.status-box { \n    background-color: #f0f8ff; \n    border-left: 4px solid #4CAF50; \n    padding: 10px; \n    margin: 10px 0; \n}\nb { \n    font-weight: bold; \n    background-color: #ffff99; \n}\n.agent-log { \n    font-family: 'Courier New', monospace; \n    font-size: 13px; \n    line-height: 1.4;\n}\n.context-box { \n    background-color: #f8f9fa; \n    padding: 15px; \n    border-radius: 8px; \n    border-left: 4px solid #007bff;\n}\n.stats-box {\n    background-color: #e8f5e8;\n    padding: 15px;\n    border-radius: 8px;\n    border-left: 4px solid #28a745;\n}\n\"\"\"\n\ndetector = AITextDetector()\nmodel_path = './ai_text_detector_model'\ntry:\n    detector.load_model(model_path)\n    print(\"Model loaded successfully for Gradio interface.\")\nexcept Exception as e:\n    print(f\"Error loading model for Gradio interface: {e}\")\n    detector = None\n\nwith gr.Blocks(css=custom_css, title=\"AI Text Detector with Agentic RAG\") as demo:\n    gr.Markdown(\"XBOT - AI\")\n    gr.Markdown(\"Enter text (min 80 words)\")\n    \n    with gr.Tabs():\n        with gr.TabItem(\"Main Tools\"):\n            input_text = gr.Textbox(\n                label=\"Input Text\",\n                placeholder=\"Enter text to classify (minimum 80 words)...\",\n                lines=10\n            )\n            word_counter = gr.HTML(value=\"<div style='color: red; font-size: 14px; margin-top: 5px;'>Word count: 0</div>\")\n            with gr.Row():\n                classify_button = gr.Button(\"Classify Text\", variant=\"primary\", size=\"lg\")\n                humanize_button = gr.Button(\"Humanize Text\", variant=\"secondary\", size=\"lg\")\n                sentiment_button = gr.Button(\"Analyze Sentiment\", variant=\"secondary\", size=\"lg\")\n            gr.Markdown(\"## Classification Results\")\n            with gr.Row():\n                with gr.Column(scale=1):\n                    prediction_output = gr.Textbox(label=\"Prediction Results\", lines=8)\n            shap_output = gr.Plot(label=\"SHAP Explanation (Top 10 Tokens)\")\n            gr.Markdown(\"## Humanization Results\")\n            humanize_status = gr.Textbox(\n                label=\"Humanization Status\",\n                lines=4,\n                placeholder=\"Humanization status and similarity metrics will appear here...\",\n                interactive=False\n            )\n            humanize_context_output = gr.Textbox(\n                label=\"Humanization Context\",\n                lines=6,\n                placeholder=\"Retrieved context used for humanization will appear here...\",\n                interactive=False\n            )\n            gr.Markdown(\"## Sentiment Analysis Results\")\n            sentiment_output = gr.Textbox(\n                label=\"Sentiment Analysis\",\n                lines=2,\n                placeholder=\"Sentiment (positive, negative, neutral) and confidence will appear here...\"\n            )\n            gr.Markdown(\"## Synonym Replacement Tool\")\n            with gr.Row():\n                with gr.Column(scale=1):\n                    word_dropdown = gr.Dropdown(\n                        label=\"Select Word to Replace\",\n                        choices=[],\n                        value=None,\n                        interactive=True\n                    )\n                with gr.Column(scale=1):\n                    synonym_dropdown = gr.Dropdown(\n                        label=\"Choose Synonym\",\n                        choices=[],\n                        value=None,\n                        interactive=True\n                    )\n                with gr.Column(scale=1):\n                    replace_button = gr.Button(\"Replace Word\", variant=\"secondary\")\n            gr.Markdown(\"## Prompt-Based Synonym Search\")\n            with gr.Row():\n                with gr.Column(scale=1):\n                    prompt_word_input = gr.Textbox(\n                        label=\"Enter Word from Modified Text\",\n                        placeholder=\"Type a word to find synonyms...\",\n                        interactive=True\n                    )\n                with gr.Column(scale=1):\n                    prompt_synonym_button = gr.Button(\"Generate Synonyms\", variant=\"secondary\")\n            prompt_synonym_output = gr.Textbox(\n                label=\"Prompt-Based Synonyms\",\n                placeholder=\"Five synonyms will appear here...\",\n                interactive=False\n            )\n            gr.Markdown(\"## Modified Text\")\n            with gr.Row():\n                with gr.Column(scale=4):\n                    updated_text = gr.Textbox(\n                        label=\"Updated Text\",\n                        lines=8,\n                        interactive=False,\n                        placeholder=\"Your modified text will appear here...\"\n                    )\n                with gr.Column(scale=1):\n                    with gr.Group():\n                        gr.Markdown(\"### Actions\")\n                        reclassify_button = gr.Button(\"Re-classify Updated Text\", variant=\"primary\")\n                        reset_button = gr.Button(\"Reset to Original\", variant=\"secondary\")\n                        copy_button = gr.Button(\"Copy to Input\", variant=\"secondary\")\n            updated_word_counter = gr.HTML(value=\"<div style='color: gray; font-size: 14px; margin-top: 5px;'>Modified word count: 0</div>\")\n            words_state = gr.State([])\n            original_text_state = gr.State(\"\")\n            changed_words_state = gr.State([])\n\n        with gr.TabItem(\"Rephraser\"):\n            with gr.Row():\n                with gr.Column(scale=3):\n                    agentic_input_text = gr.Textbox(\n                        label=\"Input Text\",\n                        placeholder=\"Enter text to rephrase (minimum 20 characters)...\",\n                        lines=10,\n                        info=\"Longer texts generally produce better results\"\n                    )\n                    with gr.Row():\n                        style_dropdown = gr.Dropdown(\n                            label=\"Rephrasing Style\",\n                            choices=[\n                                \"formal\", \"casual\", \"academic\", \"creative\", \n                                \"professional\", \"friendly\", \"neutral\", \"technical\"\n                            ],\n                            value=\"neutral\",\n                            info=\"Choose the desired writing style\"\n                        )\n                        agentic_rephrase_btn = gr.Button(\n                            \"ðŸ”„ Rephrase Text\", \n                            variant=\"primary\", \n                            size=\"lg\"\n                        )\n                with gr.Column(scale=3):\n                    agentic_output_text = gr.Textbox(\n                        label=\"Rephrased Text\",\n                        lines=10,\n                        interactive=False,\n                        info=\"The final improved version\"\n                    )\n                    agent_log = gr.Textbox(\n                        label=\"ðŸ¤– Agent Decision Log\",\n                        lines=15,\n                        interactive=False,\n                        elem_classes=[\"agent-log\"],\n                        info=\"Detailed log of the agent's decision-making process\"\n                    )\n                    agentic_context_output = gr.Textbox(\n                        label=\"ðŸ” Retrieved Context\",\n                        lines=8,\n                        interactive=False,\n                        elem_classes=[\"context-box\"],\n                        info=\"Web search results used for guidance\"\n                    )\n                    agentic_stats_output = gr.Textbox(\n                        label=\"ðŸ“Š Process Statistics\",\n                        lines=7,\n                        interactive=False,\n                        elem_classes=[\"stats-box\"],\n                        info=\"Performance metrics and statistics\"\n                    )\n\n    def update_word_count(text):\n        count = len(text.strip().split()) if text.strip() else 0\n        color = \"green\" if count >= 80 else \"red\"\n        return f\"<div style='color: {color}; font-size: 14px; margin-top: 5px;'>Word count: {count}</div>\"\n\n    input_text.change(\n        fn=update_word_count,\n        inputs=input_text,\n        outputs=word_counter\n    )\n\n    def handle_classification(text):\n        result = classify_text(text)\n        prediction, shap_plot, words, original_text = result\n        word_dropdown_update = gr.Dropdown(choices=words, value=None)\n        synonym_dropdown_update = gr.Dropdown(choices=[], value=None)\n        return prediction, shap_plot, words, word_dropdown_update, synonym_dropdown_update, original_text, original_text, []\n\n    classify_button.click(\n        fn=handle_classification,\n        inputs=[input_text],\n        outputs=[prediction_output, shap_output, words_state, word_dropdown, synonym_dropdown, original_text_state, updated_text, changed_words_state]\n    )\n\n    def handle_humanize(text):\n        status, enhanced_text, context, changed_words = humanize_text_function(text)\n        new_words = extract_words_from_text(re.sub(r'<b>|</b>', '', enhanced_text))\n        return status, enhanced_text, context, new_words, changed_words\n\n    humanize_button.click(\n        fn=handle_humanize,\n        inputs=[input_text],\n        outputs=[humanize_status, updated_text, humanize_context_output, words_state, changed_words_state]\n    )\n\n    def handle_sentiment(text):\n        if not text or not text.strip():\n            return \"No text provided for sentiment analysis.\"\n        if detector is None:\n            return \"Error: Detector not initialized\"\n        sentiment_result = detector.analyze_sentiment(text)\n        if sentiment_result[\"sentiment\"].startswith(\"error\"):\n            return f\"Error: {sentiment_result['sentiment'].replace('error: ', '')}\"\n        return f\"Sentiment: {sentiment_result['sentiment'].capitalize()} (Confidence: {sentiment_result['confidence']:.3f})\"\n\n    sentiment_button.click(\n        fn=handle_sentiment,\n        inputs=[input_text],\n        outputs=[sentiment_output]\n    )\n\n    def update_synonym_dropdown(selected_word, words_list):\n        if not selected_word or selected_word not in words_list:\n            return gr.Dropdown(choices=[], value=None)\n        if detector is None:\n            return gr.Dropdown(choices=[\"Model not loaded\"], value=None)\n        synonyms = detector.get_synonyms(selected_word)\n        return gr.Dropdown(choices=synonyms if synonyms else [\"No synonyms found\"], value=None)\n\n    word_dropdown.change(\n        fn=update_synonym_dropdown,\n        inputs=[word_dropdown, words_state],\n        outputs=synonym_dropdown\n    )\n\n    def handle_word_replacement(current_text, old_word, new_word, words_list, changed_words):\n        if not current_text or not old_word or not new_word or new_word == \"No synonyms found\":\n            return current_text, words_list, gr.Dropdown(choices=words_list, value=None), gr.Dropdown(choices=[], value=None), changed_words, update_word_count(current_text)\n        if detector is None:\n            return current_text, words_list, gr.Dropdown(choices=words_list, value=None), gr.Dropdown(choices=[], value=None), changed_words, update_word_count(current_text)\n        new_text = detector.replace_word_in_text(current_text, old_word, new_word)\n        new_words = extract_words_from_text(re.sub(r'<b>|</b>', '', new_text))\n        changed_words.append((old_word, new_word))\n        return new_text, new_words, gr.Dropdown(choices=new_words, value=None), gr.Dropdown(choices=[], value=None), changed_words, update_word_count(new_text)\n\n    replace_button.click(\n        fn=handle_word_replacement,\n        inputs=[updated_text, word_dropdown, synonym_dropdown, words_state, changed_words_state],\n        outputs=[updated_text, words_state, word_dropdown, synonym_dropdown, changed_words_state, updated_word_counter]\n    )\n\n    def generate_prompted_synonyms(text, word):\n        if not text or not word:\n            return [\"No synonyms found\"], []\n        if detector is None:\n            return [\"Model not loaded\"], []\n        synonyms, _ = detector.generate_prompted_synonyms(word, text)\n        return f\"[{', '.join(synonyms if synonyms else ['No synonyms found'])}]\", synonyms\n\n    prompt_synonym_button.click(\n        fn=generate_prompted_synonyms,\n        inputs=[updated_text, prompt_word_input],\n        outputs=[prompt_synonym_output, words_state]\n    )\n\n    def reclassify_updated_text(text):\n        if not text or not text.strip():\n            return \"No updated text to classify.\", None\n        result = classify_text(text)\n        prediction, shap_plot, words, _ = result\n        return prediction, shap_plot\n\n    reclassify_button.click(\n        fn=reclassify_updated_text,\n        inputs=[updated_text],\n        outputs=[prediction_output, shap_output]\n    )\n\n    def reset_to_original(original_text):\n        words = extract_words_from_text(original_text) if original_text else []\n        return original_text, words, gr.Dropdown(choices=words, value=None), gr.Dropdown(choices=[], value=None), [], update_word_count(original_text)\n\n    reset_button.click(\n        fn=reset_to_original,\n        inputs=original_text_state,\n        outputs=[updated_text, words_state, word_dropdown, synonym_dropdown, changed_words_state, updated_word_counter]\n    )\n\n    def copy_to_input(updated_text_content):\n        return updated_text_content\n\n    copy_button.click(\n        fn=copy_to_input,\n        inputs=updated_text,\n        outputs=input_text\n    )\n\n    agentic_rephrase_btn.click(\n        fn=agentic_rephrase_function,\n        inputs=[agentic_input_text, style_dropdown],\n        outputs=[agentic_output_text, agent_log, agentic_context_output, agentic_stats_output]\n    )\n\n# Launch the application\nif __name__ == \"__main__\":\n    demo.launch(debug=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-27T09:06:23.056954Z","iopub.execute_input":"2025-06-27T09:06:23.057311Z"}},"outputs":[{"name":"stderr","text":"[nltk_data] Downloading package wordnet to /usr/share/nltk_data...\n[nltk_data]   Package wordnet is already up-to-date!\n","output_type":"stream"},{"name":"stdout","text":"Using device: cuda\nLoading models...\nAgentic RAG Rephraser initialized successfully!\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"11c39ef8c0cc41cb90e2a3feaf12d7ed"}},"metadata":{}},{"name":"stdout","text":"Model loaded from ./ai_text_detector_model\nModel loaded successfully for Gradio interface.\n* Running on local URL:  http://127.0.0.1:7861\nIt looks like you are running Gradio on a hosted Jupyter notebook, which requires `share=True`. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n\n* Running on public URL: https://522aaf73d58ea4f621.gradio.live\n\nThis share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<div><iframe src=\"https://522aaf73d58ea4f621.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"},"metadata":{}},{"name":"stdout","text":"Loading models...\nAgentic RAG Rephraser initialized successfully!\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a2f7b6b550c843f9b8641e03f55dbcab"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8632c08b596a4b958eea3df19be5d9a6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3dfb264157b44511972ec19303908803"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"75bc407763bd44d9be4e01a6a149410b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a6eac9217b384493826277498bb71d19"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3de490ae01564d9e96b62620aa777caf"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1db3e2bacc5a4a6881ae063df84a66a2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bce00c2a834b4b07a768e78c1da5d5d6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0e76d6018a7b4432a58886f7fed94c09"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8d226735814047a6a9a7ce341568b0aa"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0f35665c6c824837b88795729b4ccb8d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ec672388d6994180a8eedbc4a549c67c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"839e9f7cf924460da22556004459933d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"88ad43858e144447a5b0546aa8194412"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"073d171947b34c9c87aa59cbe36b660d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"947ff61c07f2482eaeea572d76088067"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"72560551d219496fb78134fe08291ae4"}},"metadata":{}},{"name":"stdout","text":"Loading models...\nAgentic RAG Rephraser initialized successfully!\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d6e93f0ab07e4499a50afa879284c904"}},"metadata":{}},{"name":"stdout","text":"Model loaded from ./ai_text_detector_model\n","output_type":"stream"},{"name":"stderr","text":"Device set to use cuda:0\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/498 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Loading models...\nAgentic RAG Rephraser initialized successfully!\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"30422e15d0334f5480a1a00ab6e72be1"}},"metadata":{}},{"name":"stderr","text":"Device set to use cuda:0\n","output_type":"stream"},{"name":"stdout","text":"Model loaded from ./ai_text_detector_model\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/498 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Loading models...\nAgentic RAG Rephraser initialized successfully!\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"314a053708474fbcbb63894f3a7b8a2e"}},"metadata":{}},{"name":"stderr","text":"Device set to use cuda:0\n","output_type":"stream"},{"name":"stdout","text":"Model loaded from ./ai_text_detector_model\nLoading models...\nAgentic RAG Rephraser initialized successfully!\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e57a56a8e6084568acb487a02565a9dc"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4568370f822f47c0b293bb4873470f47"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"990eb107ceae4f20ab7bb93db5a3e43b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"916fe5f7a6294a36ab46f8890c6d97fc"}},"metadata":{}},{"name":"stdout","text":"Loading models...\nAgentic RAG Rephraser initialized successfully!\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ab519ea7b73542208d66744d173c925a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"13d9402f5ea0478993edbabe5655a698"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1b96f498ba8a4b7b961a018256c978c3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"77c8dd0f09544eb5b3fd698eebbe496e"}},"metadata":{}},{"name":"stdout","text":"Loading models...\nAgentic RAG Rephraser initialized successfully!\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"53ceb4e3031649a3901646dbb28e4a92"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"34713107b3594d1bbad7d3a2a894f171"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1925aa37b7fe4394830ed0c712c8d909"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"eb18e942d145420da994e83a8a079514"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"08e9ee6fbb804a25a697c5acb2ca35f7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"44d167ec65d549cc87ed174608d38a34"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f6513ae1390044b99d51ccc681f93be4"}},"metadata":{}},{"name":"stdout","text":"Loading models...\nAgentic RAG Rephraser initialized successfully!\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c872efcf2c594ac3a8e518c916e44276"}},"metadata":{}},{"name":"stdout","text":"Model loaded from ./ai_text_detector_model\n","output_type":"stream"},{"name":"stderr","text":"Device set to use cuda:0\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/498 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f574e8d1da1b43cb97490e2559dfeaae"}},"metadata":{}}],"execution_count":null},{"cell_type":"code","source":"!pip install gradio","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-27T08:51:10.778069Z","iopub.execute_input":"2025-06-27T08:51:10.778701Z","iopub.status.idle":"2025-06-27T08:51:20.945807Z","shell.execute_reply.started":"2025-06-27T08:51:10.778677Z","shell.execute_reply":"2025-06-27T08:51:20.944874Z"}},"outputs":[{"name":"stdout","text":"Collecting gradio\n  Downloading gradio-5.34.2-py3-none-any.whl.metadata (16 kB)\nRequirement already satisfied: aiofiles<25.0,>=22.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (22.1.0)\nRequirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (4.9.0)\nCollecting fastapi<1.0,>=0.115.2 (from gradio)\n  Downloading fastapi-0.115.14-py3-none-any.whl.metadata (27 kB)\nCollecting ffmpy (from gradio)\n  Downloading ffmpy-0.6.0-py3-none-any.whl.metadata (2.9 kB)\nCollecting gradio-client==1.10.3 (from gradio)\n  Downloading gradio_client-1.10.3-py3-none-any.whl.metadata (7.1 kB)\nCollecting groovy~=0.1 (from gradio)\n  Downloading groovy-0.1.2-py3-none-any.whl.metadata (6.1 kB)\nRequirement already satisfied: httpx>=0.24.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.28.1)\nRequirement already satisfied: huggingface-hub>=0.28.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.31.1)\nRequirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.1.6)\nRequirement already satisfied: markupsafe<4.0,>=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.0.2)\nRequirement already satisfied: numpy<3.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (1.26.4)\nRequirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.10.16)\nRequirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from gradio) (25.0)\nRequirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.2.3)\nRequirement already satisfied: pillow<12.0,>=8.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (11.1.0)\nRequirement already satisfied: pydantic<2.12,>=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.11.4)\nRequirement already satisfied: pydub in /usr/local/lib/python3.11/dist-packages (from gradio) (0.25.1)\nCollecting python-multipart>=0.0.18 (from gradio)\n  Downloading python_multipart-0.0.20-py3-none-any.whl.metadata (1.8 kB)\nRequirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (6.0.2)\nCollecting ruff>=0.9.3 (from gradio)\n  Downloading ruff-0.12.1-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (25 kB)\nCollecting safehttpx<0.2.0,>=0.1.6 (from gradio)\n  Downloading safehttpx-0.1.6-py3-none-any.whl.metadata (4.2 kB)\nCollecting semantic-version~=2.0 (from gradio)\n  Downloading semantic_version-2.10.0-py2.py3-none-any.whl.metadata (9.7 kB)\nCollecting starlette<1.0,>=0.40.0 (from gradio)\n  Downloading starlette-0.47.1-py3-none-any.whl.metadata (6.2 kB)\nCollecting tomlkit<0.14.0,>=0.12.0 (from gradio)\n  Downloading tomlkit-0.13.3-py3-none-any.whl.metadata (2.8 kB)\nRequirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.15.2)\nRequirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (4.13.2)\nCollecting uvicorn>=0.14.0 (from gradio)\n  Downloading uvicorn-0.34.3-py3-none-any.whl.metadata (6.5 kB)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.10.3->gradio) (2025.3.2)\nRequirement already satisfied: websockets<16.0,>=10.0 in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.10.3->gradio) (15.0.1)\nRequirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio) (3.10)\nRequirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\nCollecting starlette<1.0,>=0.40.0 (from gradio)\n  Downloading starlette-0.46.2-py3-none-any.whl.metadata (6.2 kB)\nRequirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio) (2025.4.26)\nRequirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio) (1.0.7)\nRequirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.24.1->gradio) (0.14.0)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (3.18.0)\nRequirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (2.32.3)\nRequirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (4.67.1)\nRequirement already satisfied: hf-xet<2.0.0,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (1.1.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy<3.0,>=1.0->gradio) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy<3.0,>=1.0->gradio) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy<3.0,>=1.0->gradio) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy<3.0,>=1.0->gradio) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy<3.0,>=1.0->gradio) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy<3.0,>=1.0->gradio) (2.4.1)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\nRequirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio) (0.7.0)\nRequirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio) (2.33.2)\nRequirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio) (0.4.0)\nRequirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (8.1.8)\nRequirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\nRequirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (14.0.0)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas<3.0,>=1.0->gradio) (1.17.0)\nRequirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (3.0.0)\nRequirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.19.1)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy<3.0,>=1.0->gradio) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy<3.0,>=1.0->gradio) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy<3.0,>=1.0->gradio) (1.3.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy<3.0,>=1.0->gradio) (2024.2.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.28.1->gradio) (3.4.2)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.28.1->gradio) (2.4.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy<3.0,>=1.0->gradio) (2024.2.0)\nRequirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\nDownloading gradio-5.34.2-py3-none-any.whl (54.3 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m54.3/54.3 MB\u001b[0m \u001b[31m30.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading gradio_client-1.10.3-py3-none-any.whl (323 kB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m323.6/323.6 kB\u001b[0m \u001b[31m20.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading fastapi-0.115.14-py3-none-any.whl (95 kB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m95.5/95.5 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading groovy-0.1.2-py3-none-any.whl (14 kB)\nDownloading python_multipart-0.0.20-py3-none-any.whl (24 kB)\nDownloading ruff-0.12.1-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.6 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m11.6/11.6 MB\u001b[0m \u001b[31m106.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n\u001b[?25hDownloading safehttpx-0.1.6-py3-none-any.whl (8.7 kB)\nDownloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\nDownloading starlette-0.46.2-py3-none-any.whl (72 kB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m72.0/72.0 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading tomlkit-0.13.3-py3-none-any.whl (38 kB)\nDownloading uvicorn-0.34.3-py3-none-any.whl (62 kB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m62.4/62.4 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading ffmpy-0.6.0-py3-none-any.whl (5.5 kB)\nInstalling collected packages: uvicorn, tomlkit, semantic-version, ruff, python-multipart, groovy, ffmpy, starlette, safehttpx, gradio-client, fastapi, gradio\nSuccessfully installed fastapi-0.115.14 ffmpy-0.6.0 gradio-5.34.2 gradio-client-1.10.3 groovy-0.1.2 python-multipart-0.0.20 ruff-0.12.1 safehttpx-0.1.6 semantic-version-2.10.0 starlette-0.46.2 tomlkit-0.13.3 uvicorn-0.34.3\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"!pip install faiss-cpu --quiet\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-27T08:52:12.163551Z","iopub.execute_input":"2025-06-27T08:52:12.164480Z","iopub.status.idle":"2025-06-27T08:52:16.889001Z","shell.execute_reply.started":"2025-06-27T08:52:12.164446Z","shell.execute_reply":"2025-06-27T08:52:16.888050Z"}},"outputs":[{"name":"stdout","text":"\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m31.3/31.3 MB\u001b[0m \u001b[31m60.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25h","output_type":"stream"}],"execution_count":4}]}